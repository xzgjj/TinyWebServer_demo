# v3 并发

TIMEOUT（超时）原因：

死锁：在 Connection::Send 和 HandleWrite 中我们都使用了 buffer_mutex_。如果主线程（Reactor）在调用 HandleWrite 时抢到了锁，而工作线程（ThreadPool）在处理 Send 时也抢锁，且两者存在某种循环依赖，就会导致服务器“卡死”。

队列积压：如果 thread_pool_ 线程数太少，或者任务执行太慢，导致 Reactor 产生的任务堆积在队列里，客户端就会因为等不到响应而超时。

SIGABRT（断言失败）原因：

GDB 显示 ConnectToServer 失败。这通常是因为服务器的监听队列（Backlog）满了，或者主线程被阻塞，无法调用 accept 来处理握手。

---

##  问题

明 V3 版本在多线程协作和协议处理上遇到了严重的性能瓶颈或逻辑死锁。

致命伤：ET 模式下的“饥饿”现象
你的 Reactor 使用的是 EPOLLET (边缘触发)。

问题：如果在一次 HandleRead 中没有把内核缓冲区的数据读干净，epoll 不会再触发第二次。
V3 特有风险：V3 引入了 input_buffer_。如果回调函数（在线程池中）解析了一半发现数据不全就返回了，而主线程因为已经处理过该事件且没新数据进来，导致剩下的数据一直堆积在内核，连接就会 TIMEOUT。
解决方案：确保 HandleRead 使用 while 循环读到 EAGAIN。

2. 线程池任务堆积 (Backlog 溢出)
GDB 显示 ConnectToServer 失败导致 assert(ret == 0) 崩溃。
原因：测试脚本（如 test_stress）瞬间发起数百个连接。如果你的主线程被某些加锁操作阻塞，或者 accept 频率跟不上，监听队列（Backlog）就会满。
优化方案：在 server.cpp 中将 listen 的第二个参数从默认值调大到 4096。

3. Connection::Send 逻辑的死锁/阻塞风险
查看你上传的 connection.cpp，你的 Send 内部直接调用了 TryFlushWriteBuffer。
问题：如果在压力测试下，write 返回 EAGAIN（内核发送缓冲区满了），你的代码可能在原地打转或者没有正确处理后续的 EPOLLOUT 事件。
优化建议：对于大流量测试，应该将数据放入 write_buffer_ 后立即返回，由 Reactor 监听可写事件来发送。


---

### 

TIMEOUT 以及 GDB 里的 SIGABRT 暴露了多线程环境下的一个经典难题：非阻塞网络编程中的“写溢出”与事件丢失。
现状分析：为什么单连接过了，并发却挂了？
从日志看，连接能建立（New connection），也能关闭（Socket closed），但客户端认为超时。这通常是因为：

内核缓冲区满（EAGAIN）：在高并发下，服务器 send 数据非常快，很快就把操作系统的 TCP 发送缓冲区填满了。
事件丢失：如果 write 返回 EAGAIN，而我们没有告诉 Epoll 去监听这个 Socket 的“可写”事件（EPOLLOUT），那剩下的一半数据就永远发不出去，客户端会一直等，直到超时。

 深度优化方案:

要修改 Connection 和 EpollReactor 的协作方式，实现真正的非阻塞异步发送
